{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce05122-8e8c-4b8b-b530-46140b083c2b",
   "metadata": {},
   "source": [
    "# Evaluating Linear Models: Metrics and Meaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1b1d0-4b62-4032-ba43-79bf0e37ac78",
   "metadata": {},
   "source": [
    "After fitting and interpreting a linear model, evaluation metrics are often\n",
    "used to summarize model performance. However, metrics must be interpreted\n",
    "in context and with caution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4678fb0b-6a18-4d06-823c-161d0cbf776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "df = pd.read_csv(\"../data/example_relationships.csv\")\n",
    "\n",
    "X = df[['x']]\n",
    "y = df['y']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219b577-a533-4d6e-8702-0b996273f1ee",
   "metadata": {},
   "source": [
    "## R² (Coefficient of Determination)\n",
    "\n",
    "R² represents the proportion of variance in the response variable\n",
    "explained by the model. High R² values indicate a strong linear fit,\n",
    "but do not guarantee a meaningful or causal relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2ab0ce-cebf-4f8a-ace8-25b3c943cf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932491642595177"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = r2_score(y, y_pred)\n",
    "r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520126b5-39af-4b76-b0d2-2ba532ad149f",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)\n",
    "\n",
    "MAE measures the average absolute difference between observed and predicted\n",
    "values. Unlike R², it is expressed in the same units as the response variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0f29ff-bd8c-44b6-9ab6-5feb23b0a76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.349090909090909"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(y, y_pred)\n",
    "mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c158130-6fce-488b-aad0-2522a96b0b70",
   "metadata": {},
   "source": [
    "A high R² combined with a low MAE suggests that the model fits the observed\n",
    "data well. However, these metrics do not capture model validity outside the\n",
    "observed range, sensitivity to outliers, or causal relevance. Metrics are\n",
    "summaries, not guarantees of insight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b026c096-9215-4534-8862-ac8cb52a3c77",
   "metadata": {},
   "source": [
    "## A Note of Caution\n",
    "\n",
    "Model evaluation metrics are useful tools, but they should not be interpreted\n",
    "in isolation. Understanding the data, the assumptions, and the context\n",
    "remains essential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e3ed3-8e51-433f-8ff8-97ac76fe97de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ds-env)",
   "language": "python",
   "name": "ds-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
